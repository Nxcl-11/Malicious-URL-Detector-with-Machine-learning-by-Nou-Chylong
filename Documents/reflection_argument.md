# Reflection & Argument

This project helped me understand the vital role feature engineering plays in classification tasks. For instance, extracting features such as URL length, the presence of IP addresses, and counts of special characters ended up being the most predictive indicators of phishing attempts. Detecting malicious URLs is not only about achieving high accuracy (86.35 %), but also about catching as many threats as possible—during development, I noticed the model’s recall on malicious URLs was 73 %, meaning some threats still slipped through. Ensuring the model provides real-world value means balancing precision and recall so that security analysts can trust its alerts rather than chasing false positives.

The Random Forest model performed effectively in identifying threats based on these engineered features, confirming its strength on structured data. However, I faced challenges with the class imbalance early on—tweaking class_weight and experimenting with under-sampling were key steps to improving detection rates.

Looking forward, this project opened my eyes to possibilities beyond traditional models. I plan to experiment with neural networks to capture deeper, more complex patterns hidden within URL structures. By integrating real-time URL stream analysis (for example, flagging URLs as they appear in email traffic) and applying advanced techniques like deep learning, I believe the system can become more adaptive and accurate in handling evolving cyber threats.
